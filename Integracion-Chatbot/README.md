# ü§ñ Integraci√≥n Chatbot: Agente Inmobiliario Cognitivo (v3.3)

> **Arquitectura Integral e Implementaci√≥n de Asistente Inmobiliario Cognitivo:**  
> Sinergia entre PANELIN-API, WhatsApp Cloud, OpenAI v2 y Google Cloud Run

---

## Quick Start

```bash
# 1. Clonar el repositorio
git clone https://github.com/matiasportugau-ui/Integracion-Chatbot.git
cd Integracion-Chatbot

# 2. Crear entorno virtual e instalar dependencias
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 3. Configurar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales reales

# 4. Ejecutar el servidor
uvicorn src.main:app --host 0.0.0.0 --port 8080

# 5. Ejecutar el servidor MCP (en otra terminal)
python mcp_server/panelin_mcp.py
```

---

## √çndice

1. [Fundamentos Arquitect√≥nicos y Despliegue en Google Cloud Run](#1-fundamentos-arquitect√≥nicos-y-despliegue-en-google-cloud-run)
2. [Integraci√≥n de la Interfaz Conversacional: WhatsApp Cloud API](#2-integraci√≥n-de-la-interfaz-conversacional-whatsapp-cloud-api)
3. [Evoluci√≥n Cognitiva: OpenAI Assistants API v2, Responses API y RAG](#3-evoluci√≥n-cognitiva-openai-assistants-api-v2-responses-api-y-rag)
4. [Sincronizaci√≥n de Datos Inmobiliarios: PANELIN-API (Inmoenter)](#4-sincronizaci√≥n-de-datos-inmobiliarios-panelin-api-inmoenter)
5. [Persistencia Multiturno y Control de Concurrencia con Cloud Firestore](#5-persistencia-multiturno-y-control-de-concurrencia-con-cloud-firestore)
6. [El Protocolo de Escalado Humano (Human-in-the-Loop)](#6-el-protocolo-de-escalado-humano-human-in-the-loop)
7. [Gesti√≥n Avanzada de Multimedia: Transmisi√≥n de PDFs](#7-gesti√≥n-avanzada-de-multimedia-transmisi√≥n-de-contratos-y-dossiers-en-pdf)
8. [Implementaci√≥n del C√≥digo Fuente (FastAPI As√≠ncrono)](#8-implementaci√≥n-del-c√≥digo-fuente-fastapi-as√≠ncrono)
9. [Gu√≠a de Implementaci√≥n Asistida por IA (Cursor IDE)](#9-gu√≠a-de-implementaci√≥n-asistida-por-ia-cursor-ide)

---

## Estructura del Proyecto

```
Integracion-Chatbot/
‚îú‚îÄ‚îÄ .cursor/rules/project-rules.mdc   # Reglas Cursor IDE (Secci√≥n 9.1)
‚îú‚îÄ‚îÄ .env.example                       # Template de variables de entorno
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ Dockerfile                         # Deploy en Google Cloud Run
‚îú‚îÄ‚îÄ README.md                          # Este documento
‚îú‚îÄ‚îÄ requirements.txt                   # Dependencias Python
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py                      # Configuraci√≥n centralizada
‚îÇ   ‚îú‚îÄ‚îÄ firestore_client.py            # Gesti√≥n de sesiones Firestore
‚îÇ   ‚îú‚îÄ‚îÄ api_meta.py                    # Capa de transporte WhatsApp
‚îÇ   ‚îú‚îÄ‚îÄ openai_router.py               # Enrutador OpenAI Responses API
‚îÇ   ‚îî‚îÄ‚îÄ main.py                        # FastAPI webhook principal
‚îú‚îÄ‚îÄ mcp_server/
‚îÇ   ‚îî‚îÄ‚îÄ panelin_mcp.py                 # Servidor MCP para CRM Inmoenter
‚îî‚îÄ‚îÄ scripts/
    ‚îî‚îÄ‚îÄ sync_vector_store.py           # Sincronizaci√≥n Vector Store
```

---

## 1. Fundamentos Arquitect√≥nicos y Despliegue en Google Cloud Run

El ecosistema t√©cnico se estructura como una **arquitectura orientada a eventos y microservicios sin estado**. Google Cloud Run act√∫a como el n√∫cleo orquestador, proporcionando un endpoint HTTPS seguro y escalable que procesa los webhooks entrantes de Meta y coordina las llamadas as√≠ncronas hacia la API de OpenAI y el CRM inmobiliario.

La naturaleza *"stateless"* (sin estado) de Cloud Run exige que cualquier memoria a corto o largo plazo, as√≠ como los bloqueos transaccionales, se externalicen a servicios dedicados como **Firestore** y los **almacenes vectoriales de OpenAI**. Esta decisi√≥n de dise√±o garantiza que las instancias del contenedor puedan crearse o destruirse din√°micamente seg√∫n las fluctuaciones del tr√°fico de red sin perder el contexto de las negociaciones con los clientes.

Una consideraci√≥n cr√≠tica en el dise√±o de infraestructura para agentes cognitivos basados en Python es la **gesti√≥n de la concurrencia**. Las comunicaciones con las API de OpenAI, Meta y PANELIN-API involucran predominantemente operaciones limitadas por entrada/salida (I/O-bound) y tiempos de espera de red. Por ello, la industria ha abandonado los frameworks s√≠ncronos tradicionales (como Flask) en favor de **FastAPI**. El soporte nativo de FastAPI para operaciones as√≠ncronas (`async/await`) resulta cr√≠tico y altamente eficiente al orquestar llamadas de red concurrentes, permitiendo escalar el rendimiento del contenedor de Cloud Run y procesar docenas de mensajes de WhatsApp simult√°neamente sin bloquear el hilo principal de ejecuci√≥n.

Adicionalmente, la configuraci√≥n de facturaci√≥n y asignaci√≥n de CPU en Google Cloud Run tiene implicaciones directas en el comportamiento de las integraciones de IA. Si el sistema requiere ejecutar procesos anal√≠ticos en segundo plano despu√©s de devolver la respuesta inicial al webhook de Meta (para evitar timeouts en la API de WhatsApp), se debe configurar Cloud Run con la opci√≥n de **"CPU siempre asignada"** (*CPU always allocated*).

La infraestructura descrita asegura que la plataforma no solo sea reactiva, sino que posea la **resiliencia sist√©mica** necesaria para manejar picos de tr√°fico originados por campa√±as masivas.

---

## 2. Integraci√≥n de la Interfaz Conversacional: WhatsApp Cloud API

La selecci√≥n de la **API oficial de WhatsApp Cloud** administrada por Meta es un mandato arquitect√≥nico irrenunciable para operaciones a escala empresarial, garantizando estabilidad frente a bloqueos y soporte oficial de plantillas.

La interacci√≥n entre el cl√∫ster de Cloud Run y la infraestructura de Meta se rige por un **paradigma de webhooks basado en eventos**. Meta requiere que el servidor exponga un endpoint p√∫blico que responda a un desaf√≠o criptogr√°fico inicial para verificar la propiedad del dominio.

### Seguridad: Verificaci√≥n HMAC

M√°s all√° de la verificaci√≥n inicial, la seguridad operacional continua exige validar la cabecera `X-Hub-Signature-256`. El middleware en FastAPI debe computar din√°micamente el c√≥digo HMAC utilizando el algoritmo **SHA-256** sobre la carga √∫til bruta de la petici√≥n, empleando el `App Secret` como clave criptogr√°fica.

```python
async def verify_signature(request: Request):
    signature = request.headers.get("X-Hub-Signature-256")
    payload = await request.body()
    expected = hmac.new(APP_SECRET.encode(), payload, hashlib.sha256).hexdigest()
    if not hmac.compare_digest(signature, f"sha256={expected}"):
        raise HTTPException(status_code=401, detail="Firma inv√°lida")
```

### Ventana de 24 Horas

El modelo comercial de Meta impone una **restricci√≥n de ventana de 24 horas**. Cuando un cliente env√≠a un mensaje, se abre una ventana durante la cual las respuestas de formato libre incurren en tarifas de sesi√≥n. Si el agente necesita contactar al prospecto fuera de esta ventana temporal, el sistema est√° estrictamente obligado a utilizar **"Mensajes de Plantilla"** (*Template Messages*) preaprobados por Meta.

La arquitectura debe monitorear el tiempo transcurrido desde la √∫ltima interacci√≥n (almacenada en Firestore) y cambiar autom√°ticamente de formato si el umbral se excede.

---

## 3. Evoluci√≥n Cognitiva: OpenAI Assistants API v2, Responses API y RAG

El n√∫cleo de comprensi√≥n del lenguaje natural reside en los modelos fundacionales de OpenAI. Si bien la arquitectura actual se basa en la Assistants API v2, el ecosistema est√° en plena transici√≥n.

> ‚ö†Ô∏è **Nota de Migraci√≥n:** OpenAI ha anunciado la eventual depreciaci√≥n de la API de Asistentes en favor de la nueva y m√°s flexible **Responses API** acoplada con el est√°ndar **Model Context Protocol (MCP)**. Este proyecto implementa la Responses API como est√°ndar.

Dise√±ar el sistema con una clara separaci√≥n de responsabilidades facilita la migraci√≥n: el enrutamiento y el historial en Firestore se mantienen id√©nticos, mientras que solo el objeto de llamada a la IA cambia a la nueva sintaxis de *Prompts* y *Conversations*.

### 3.1. Gesti√≥n de Almacenes Vectoriales (Vector Stores)

Los **Vector Stores** permiten que el conocimiento profundo de la agencia se consolide en un repositorio centralizado e indexado.

> ‚ö†Ô∏è **Pol√≠tica de Retenci√≥n:** Los almacenes vectoriales creados din√°micamente y adjuntados a hilos de conversaci√≥n heredan una pol√≠tica de expiraci√≥n predeterminada de **7 d√≠as** tras su √∫ltima actividad. Para garantizar que el inventario inmobiliario maestro permanezca disponible ininterrumpidamente, se debe sobrescribir expl√≠citamente `expires_after` estableci√©ndola a valores prolongados o nulos.

#### Flujo RAG (Generaci√≥n Aumentada por Recuperaci√≥n) Inmobiliario

1. **Ingesta y Segmentaci√≥n:** Los documentos (XML parseados a JSON/Markdown) se suben y asocian al almac√©n vectorial. OpenAI aplica algoritmos de fragmentaci√≥n est√°ticos o din√°micos para preservar el contexto.
2. **Transformaci√≥n Vectorial:** Se convierten a representaciones num√©ricas mediante modelos de embeddings (ej. `text-embedding-3-large`).
3. **Recuperaci√≥n Sem√°ntica:** Al recibir una consulta ("Busco √°tico en la costa"), la herramienta `file_search` realiza una b√∫squeda de similitud espacial y extrae los fragmentos relevantes para inyectarlos en la ventana de contexto del LLM.

### 3.2. Model Context Protocol (MCP) para Integraci√≥n Externa

Para interactuar en tiempo real con datos que no est√°n en el Vector Store (por ejemplo, buscar disponibilidad de calendario de un agente o insertar un nuevo lead en el CRM Inmoenter), la arquitectura moderna recomienda el uso del **Model Context Protocol (MCP)**.

En lugar de definir esquemas JSON de `function_calling` fr√°giles en cada solicitud, un servidor MCP act√∫a como un **conector estandarizado**. El LLM descubre autom√°ticamente las herramientas expuestas por el servidor MCP (ej. `create_lead`, `fetch_latest_properties`) y delega la ejecuci√≥n de la API REST subyacente de PANELIN de manera segura y controlada.

```python
# Integraci√≥n MCP en la Responses API
response = await client.responses.create(
    model="gpt-4o",
    input=user_text,
    tools=[
        {"type": "file_search", "max_num_results": 3},
        {"type": "mcp", "server_url": "http://localhost:8080"}
    ]
)
```

---

## 4. Sincronizaci√≥n de Datos Inmobiliarios: PANELIN-API (Inmoenter)

La inteligencia del agente conversacional depende de la **frescura de los datos** en la plataforma Inmoenter, accesible a trav√©s de PANELIN-API y sus feeds de sindicaci√≥n XML (XCP / KML3).

### Flujo de Sincronizaci√≥n

1. Un proceso cronometrado (**Cloud Scheduler**) ejecuta una petici√≥n `GET` nocturna hacia los endpoints regionales de Inmoenter utilizando una API KEY.
2. Una vez que el documento XML es descargado en la memoria, el middleware de Python lo transforma en documentos legibles para el LLM.
3. Los documentos transformados se sincronizan al Vector Store de OpenAI (ver `scripts/sync_vector_store.py`).

### Integraci√≥n Bidireccional

Cuando la IA cualifica a un prospecto en WhatsApp, las variables (presupuesto, ubicaci√≥n) se extraen sem√°nticamente. Posteriormente, utilizando herramientas invocables (a trav√©s del puente MCP), el backend de Cloud Run realiza una petici√≥n REST `POST` a Inmoenter para crear el lead y la "demanda", asign√°ndolo autom√°ticamente a los embudos de venta de los agentes humanos.

---

## 5. Persistencia Multiturno y Control de Concurrencia con Cloud Firestore

La API de OpenAI delega la gesti√≥n de la memoria secuencial, pero es responsabilidad de la capa de integraci√≥n vincular cada n√∫mero de WhatsApp con su hilo correspondiente.

### Esquema Documental

Google Cloud Firestore utiliza el n√∫mero de tel√©fono (`wa_id`) como clave primaria:

| Campo | Tipo | Descripci√≥n |
|-------|------|-------------|
| `wa_id` | `string` | N√∫mero de tel√©fono del cliente |
| `thread_id` | `string` | ID del hilo de conversaci√≥n OpenAI |
| `ai_active` | `boolean` | `true` = IA controla, `false` = humano controla |
| `last_interaction` | `timestamp` | Marca temporal de √∫ltima interacci√≥n |

### Control de Concurrencia

Para manejar las r√°fagas de mensajes as√≠ncronos t√≠picos de WhatsApp y evitar **condiciones de carrera** (creaci√≥n de m√∫ltiples hilos para el mismo usuario de forma simult√°nea), las operaciones de lectura y escritura en Firestore se encapsulan dentro de **transacciones at√≥micas** del SDK de Firebase.

```python
@firestore.transactional
def execute_transaction(transaction, ref):
    snapshot = ref.get(transaction=transaction)
    # ... l√≥gica at√≥mica ...
    transaction.update(ref, {"last_interaction": now, "ai_active": ai_active})
    return ai_active, thread_id
```

---

## 6. El Protocolo de Escalado Humano (Human-in-the-Loop)

Depender exclusivamente de la IA representa un riesgo para negociaciones sensibles. El patr√≥n de **"Escalado Humano"** (*Human Handoff*) act√∫a como el freno de emergencia del ecosistema.

### Flujo de Escalado

```
Cliente dice "quiero hablar con un agente"
    ‚Üí LLM detecta intenci√≥n de asistencia humana
    ‚Üí ai_active = false en Firestore
    ‚Üí IA responde: "Transfiriendo a un agente comercial..."
    ‚Üí Mensajes subsiguientes ‚Üí Cloud Run lee ai_active=false ‚Üí HTTP 200 silencioso
    ‚Üí Operador humano interact√∫a libremente

Timeout 24h sin interacci√≥n del operador:
    ‚Üí ai_active revierte a true autom√°ticamente
```

### Keywords de Activaci√≥n

```python
HANDOFF_KEYWORDS = ["humano", "agente", "asesor"]

if any(word in user_text.lower() for word in HANDOFF_KEYWORDS):
    disable_ai_for_human(wa_id)
    return "Un agente comercial revisar√° este chat a la brevedad."
```

---

## 7. Gesti√≥n Avanzada de Multimedia: Transmisi√≥n de Contratos y Dossiers en PDF

La capacidad de despachar documentos t√©cnicos (PDF) requiere una **orquestaci√≥n en dos fases as√≠ncronas** con la Graph API de Meta.

### Fase 1: Ingesta a Meta (obtenci√≥n del `media_id`)

El sistema descarga el PDF o lo genera en memoria, y formula un `POST` al endpoint `/media` codificado como `multipart/form-data`.

> ‚ö†Ô∏è **Cr√≠tico:** En Python (usando `httpx`), enviar el archivo como una tupla estructurada: `('filename.pdf', file_bytes, 'application/pdf')`. Omitir esta estructura provocar√° un error `OAuthException Code 100` por parte de los servidores de Meta.

### Fase 2: Transmisi√≥n del Mensaje

Se emite una segunda petici√≥n `POST` al endpoint `/messages` con una carga √∫til JSON que inyecta el `media_id` recuperado, junto con el nombre del archivo (`filename`) y un texto descriptivo (`caption`).

```python
payload = {
    "messaging_product": "whatsapp", "to": to, "type": "document",
    "document": {"id": media_id, "filename": filename, "caption": "Documento adjunto."}
}
```

---

## 8. Implementaci√≥n del C√≥digo Fuente (FastAPI As√≠ncrono)

Para maximizar el rendimiento en Cloud Run y evitar el bloqueo del GIL en Python durante llamadas I/O intensivas, la implementaci√≥n se basa en **FastAPI** y clientes HTTP as√≠ncronos (`httpx` y `AsyncOpenAI`).

### 8.1. Dependencias (`requirements.txt`)

```
fastapi>=0.109.0
uvicorn>=0.27.0
httpx>=0.26.0
openai>=1.14.0
firebase-admin>=6.5.0
fastmcp>=0.1.0
python-dotenv>=1.0.1
```

### 8.2. Arquitectura Modular

La implementaci√≥n sigue una **arquitectura modular** en lugar de un archivo monol√≠tico, facilitando el mantenimiento y las pruebas unitarias:

| M√≥dulo | Responsabilidad |
|--------|----------------|
| `src/config.py` | Configuraci√≥n centralizada de variables de entorno |
| `src/firestore_client.py` | Gesti√≥n transaccional de sesiones en Firestore |
| `src/api_meta.py` | Capa de transporte hacia WhatsApp Cloud API |
| `src/openai_router.py` | Enrutamiento de inferencia con OpenAI Responses API |
| `src/main.py` | Webhook FastAPI principal con verificaci√≥n HMAC |
| `mcp_server/panelin_mcp.py` | Servidor MCP para integraci√≥n CRM Inmoenter |

### 8.3. Despliegue con Docker

```dockerfile
FROM python:3.12-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8080"]
```

```bash
# Build y deploy a Cloud Run
gcloud builds submit --tag gcr.io/PROJECT_ID/integracion-chatbot
gcloud run deploy integracion-chatbot \
  --image gcr.io/PROJECT_ID/integracion-chatbot \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --set-env-vars "VERIFY_TOKEN=...,WHATSAPP_TOKEN=..."
```

---

## 9. Gu√≠a de Implementaci√≥n Asistida por IA (Cursor IDE)

La arquitectura descrita representa un sistema complejo con m√∫ltiples puntos de integraci√≥n. Para acelerar el desarrollo y reducir la fricci√≥n, se recomienda encarecidamente la utilizaci√≥n de entornos de desarrollo impulsados por IA, como **Cursor IDE**.

### 9.1. Definici√≥n de Reglas de Proyecto (`.cursor/rules/`)

Para que el modelo de lenguaje mantenga la coherencia arquitect√≥nica y no genere c√≥digo con librer√≠as obsoletas (como la antigua Assistants API), es mandatorio establecer **reglas de proyecto**. Cursor soporta archivos Markdown con metadatos (formato `.mdc`) almacenados en el directorio `.cursor/rules/`.

- **Forzar** el uso de FastAPI y httpx as√≠ncrono para las integraciones web.
- **Especificar expl√≠citamente** el uso de la Responses API de OpenAI y el est√°ndar MCP.
- **Documentar** el patr√≥n Human Handoff con Firestore para alinear al modelo.

### 9.2. Modos de Interacci√≥n: Composer vs. Chat

| Herramienta | Uso Ideal |
|-------------|-----------|
| **Composer (Agent Mode)** | Andamiaje y tareas multi-archivo: *"Genera la estructura de directorios, el archivo main.py con FastAPI y el panelin_mcp.py bas√°ndote en las reglas del proyecto"* |
| **Chat** | Depuraci√≥n l√≠nea por l√≠nea: *"¬øPor qu√© el webhook de Meta est√° devolviendo un error de validaci√≥n HMAC en esta funci√≥n?"* |

### 9.3. Gesti√≥n de Contexto mediante Indexaci√≥n Sem√°ntica

Al trabajar con m√∫ltiples m√≥dulos, el agente necesita contexto preciso. Se recomienda invocar dependencias expl√≠citamente utilizando el atajo `@` seguido del nombre del archivo o carpeta en el chat (por ejemplo, `@api_meta.py` o `@firestore_client.py`).

### 9.4. Planificaci√≥n, Autonom√≠a y Tolerancia a Fallos

- **Plan Mode:** Generar un plan de implementaci√≥n antes de escribir c√≥digo masivo. Guardar en `.cursor/plans/`.
- **YOLO Mode + TDD:** El agente ejecuta comandos en terminal, arranca el servidor (`uvicorn`), verifica errores de linting o ejecuta pruebas (`pytest`), corrigiendo recursivamente hasta que el sistema funcione.
- **Restore Checkpoint:** Si la IA genera c√≥digo contraproducente, revertir con la funcionalidad de checkpoint en lugar de forzar correcciones iterativas.

---

## Licencia

Este proyecto es propiedad de [matiasportugau-ui](https://github.com/matiasportugau-ui). Todos los derechos reservados.
